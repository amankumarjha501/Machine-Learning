{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM2jAugsHqXsvEyoEZ7nEM4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"LvVSOky_W5b3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":2,"metadata":{"id":"7iW9g04YE_Pr","executionInfo":{"status":"ok","timestamp":1704698905158,"user_tz":-330,"elapsed":1689,"user":{"displayName":"aman kumar","userId":"16741885519187176997"}}},"outputs":[],"source":["#Basic and most important libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#Classifiers\n","from sklearn.ensemble import AdaBoostClassifier , GradientBoostingClassifier,RandomForestClassifier\n","from sklearn.linear_model import LinearRegression\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","#Model evaluation tools\n","from sklearn.metrics import classification_report , accuracy_score , confusion_matrix\n","from sklearn.metrics import f1_score\n","from sklearn.model_selection import cross_val_score\n","\n","#Data processing functions\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","le = LabelEncoder()\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","source":["import nltk\n","from nltk.corpus import stopwords\n","from nltk.tokenize import word_tokenize\n","from nltk.stem import PorterStemmer\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Download NLTK resources (run this once)\n","nltk.download('punkt')\n","nltk.download('stopwords')\n","\n","# Sample dataset for binary text classification\n","positive_reviews = [\"I love this product!\", \"It's amazing.\", \"Great purchase.\"]\n","negative_reviews = [\"Not worth the money.\", \"Disappointing.\", \"Terrible experience.\"]\n","\n","# Preprocessing: Tokenization, Stopword Removal, and Stemming\n","stop_words = set(stopwords.words('english'))\n","ps = PorterStemmer()\n","\n","def preprocess_text(text):\n","    words = word_tokenize(text.lower())\n","    words = [ps.stem(word) for word in words if word.isalnum() and word not in stop_words]\n","    return ' '.join(words)\n","\n","positive_reviews = [preprocess_text(review) for review in positive_reviews]\n","negative_reviews = [preprocess_text(review) for review in negative_reviews]\n","\n","# Creating feature vectors using Bag-of-Words model\n","vectorizer = CountVectorizer()\n","X = vectorizer.fit_transform(positive_reviews + negative_reviews).toarray()\n","y = [1] * len(positive_reviews) + [0] * len(negative_reviews)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Train a Naive Bayes classifier\n","classifier = MultinomialNB()\n","classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = classifier.predict(X_test)\n","\n","# Evaluate the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f\"Accuracy: {accuracy:.2f}\")\n","\n","print(\"\\nClassification Report:\")\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cYgOnZcWZytz","executionInfo":{"status":"ok","timestamp":1704698908929,"user_tz":-330,"elapsed":1991,"user":{"displayName":"aman kumar","userId":"16741885519187176997"}},"outputId":"103e6199-f524-4f22-c09a-b1238b90943f"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy: 0.00\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","           0       0.00      0.00      0.00       0.0\n","           1       0.00      0.00      0.00       2.0\n","\n","    accuracy                           0.00       2.0\n","   macro avg       0.00      0.00      0.00       2.0\n","weighted avg       0.00      0.00      0.00       2.0\n","\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"a7Om6FUqb2yk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hpDYjGdCGAhY"},"outputs":[],"source":["data = pd.read_csv(\"https://raw.githubusercontent.com/Premalatha-success/Datasets/main/h1n1_vaccine_prediction.csv\")\n","data.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1xabZtXNGWpV"},"outputs":[],"source":["data.shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wwNHJEojHdCW"},"outputs":[],"source":["data.dtypes"]},{"cell_type":"code","source":["from flask import Flask, render_template, request, jsonify\n","import joblib\n","\n","app = Flask(__name__)\n","\n","# Load your trained machine learning model\n","model = joblib.load(\"your_model.pkl\")\n","\n","@app.route('/')\n","def home():\n","    return render_template('index.html')\n","\n","@app.route('/predict', methods=['POST'])\n","def predict():\n","    try:\n","        # Get input data from the form\n","        feature1 = float(request.form['feature1'])\n","        feature2 = float(request.form['feature2'])\n","\n","        # Make a prediction using the loaded model\n","        prediction = model.predict([[feature1, feature2]])\n","\n","        # Return the result to the frontend\n","        return render_template('index.html', prediction=prediction[0])\n","\n","    except Exception as e:\n","        return render_template('index.html', error=\"Error: {}\".format(str(e)))\n","\n","if __name__ == '__main__':\n","    app.run(debug=True)\n"],"metadata":{"id":"v2NL3wV2YwCs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.svm import SVC\n","from sklearn.metrics import accuracy_score, classification_report\n","\n","# Load the Iris dataset as an example\n","iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target\n","\n","# Split the dataset into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Standardize features by removing the mean and scaling to unit variance\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Create an SVM classifier with a radial basis function (RBF) kernel\n","svm_classifier = SVC(kernel='rbf', C=1.0, gamma='scale', random_state=42)\n","\n","# Train the SVM classifier\n","svm_classifier.fit(X_train, y_train)\n","\n","# Make predictions on the test set\n","y_pred = svm_classifier.predict(X_test)\n","\n","# Evaluate the performance of the classifier\n","accuracy = accuracy_score(y_test, y_pred)\n","classification_report_str = classification_report(y_test, y_pred)\n","\n","print(f\"Accuracy: {accuracy}\")\n","print(\"Classification Report:\\n\", classification_report_str)\n","\n","# Visualize the decision boundary (2D plot for simplicity)\n","# Note: This visualization is specific to the first two features of the Iris dataset\n","plt.figure(figsize=(8, 6))\n","\n","# Plot the decision boundary\n","h = .02  # step size in the mesh\n","x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n","y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n","xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n","\n","Z = svm_classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n","Z = Z.reshape(xx.shape)\n","\n","plt.contourf(xx, yy, Z, cmap=plt.cm.coolwarm, alpha=0.8)\n","plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.coolwarm, edgecolors='k')\n","plt.title('SVM Decision Boundary')\n","plt.xlabel('Feature 1')\n","plt.ylabel('Feature 2')\n","\n","plt.show()\n"],"metadata":{"id":"I1wWUELgb4s6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import tensorflow as tf\n","import numpy as np\n","\n","# Create the XOR dataset\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n","y = np.array([[0], [1], [1], [0]], dtype=np.float32)\n","\n","# Define the neural network architecture\n","model = tf.keras.Sequential([\n","    tf.keras.layers.Dense(2, input_dim=2, activation='relu'),  # Hidden layer with 2 neurons and ReLU activation\n","    tf.keras.layers.Dense(1, activation='sigmoid')  # Output layer with 1 neuron and sigmoid activation for binary classification\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X, y, epochs=10000, verbose=0)\n","\n","# Evaluate the model\n","loss, accuracy = model.evaluate(X, y)\n","print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n","\n","# Make predictions\n","predictions = model.predict(X)\n","predicted_labels = (predictions > 0.5).astype(np.float32)\n","print(\"Predictions:\\n\", predicted_labels)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"otb3EBodcKiG","executionInfo":{"status":"ok","timestamp":1704698903478,"user_tz":-330,"elapsed":72119,"user":{"displayName":"aman kumar","userId":"16741885519187176997"}},"outputId":"42fcb35f-fe4e-45cb-90c1-a05ea253ec75"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["1/1 [==============================] - 0s 236ms/step - loss: 0.6931 - accuracy: 0.5000\n","Loss: 0.6931471824645996, Accuracy: 0.5\n","1/1 [==============================] - 0s 138ms/step\n","Predictions:\n"," [[0.]\n"," [0.]\n"," [0.]\n"," [0.]]\n"]}]}]}